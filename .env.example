# This is the model agnostic .env setup you can provide any model of any model provider

# You can find the model provide names in the following links
# url -  https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html

#example openai, anthropic, google_genai, groq
MODEL_PROVIDER_FOR_CHAT = "google_genai"  
#example o3-mini, gemini-1.5-pro, gemini-1.5-flash, llama3-8b-8192, gpt-3.5-turbo-instruct
MODEL_NAME_FOR_CHAT = "gemini-2.0-flash"  

#example openai, anthropic, google_genai, groq
MODEL_PROVIDER_FOR_SUMMARY = "groq"  
#example o3-mini, gemini-1.5-pro, gemini-1.5-flash, llama3-8b-8192, gpt-3.5-turbo-instruct
MODEL_NAME_FOR_SUMMARY = "llama3-8b-8192"  

GROQ_API_KEY = "gsk_---"
GOOGLE_API_KEY = "AI----"
OPENAI_API_KEY = ""
